{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPY+oQS3bj3T4nk9oezMZdT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maha3069/youtube_tuto/blob/main/langgraph.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "1Kq5dv7YDmvO",
        "outputId": "68b246b2-2815-4558-b3af-c6add2ee98d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.12/dist-packages (0.6.8)\n",
            "Requirement already satisfied: langchain-core>=0.1 in /usr/local/lib/python3.12/dist-packages (from langgraph) (0.3.77)\n",
            "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (2.1.2)\n",
            "Requirement already satisfied: langgraph-prebuilt<0.7.0,>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (0.6.4)\n",
            "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /usr/local/lib/python3.12/dist-packages (from langgraph) (0.2.9)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langgraph) (2.11.9)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.5.0)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (0.4.31)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (6.0.3)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (4.15.0)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (25.0)\n",
            "Requirement already satisfied: ormsgpack>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph) (1.10.0)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (0.4.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core>=0.1->langgraph) (3.0.0)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (2.32.4)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (0.25.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (2.5.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.3.1)\n",
            "Requirement already satisfied: langchain_groq in /usr/local/lib/python3.12/dist-packages (0.3.8)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.75 in /usr/local/lib/python3.12/dist-packages (from langchain_groq) (0.3.77)\n",
            "Requirement already satisfied: groq<1,>=0.30.0 in /usr/local/lib/python3.12/dist-packages (from langchain_groq) (0.32.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq<1,>=0.30.0->langchain_groq) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq<1,>=0.30.0->langchain_groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from groq<1,>=0.30.0->langchain_groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from groq<1,>=0.30.0->langchain_groq) (2.11.9)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq<1,>=0.30.0->langchain_groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from groq<1,>=0.30.0->langchain_groq) (4.15.0)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.75->langchain_groq) (0.4.31)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.75->langchain_groq) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.75->langchain_groq) (1.33)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.75->langchain_groq) (6.0.3)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.75->langchain_groq) (25.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->groq<1,>=0.30.0->langchain_groq) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.30.0->langchain_groq) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.30.0->langchain_groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.30.0->langchain_groq) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<1.0.0,>=0.3.75->langchain_groq) (3.0.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.75->langchain_groq) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.75->langchain_groq) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.75->langchain_groq) (2.32.4)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.75->langchain_groq) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.30.0->langchain_groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.30.0->langchain_groq) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.30.0->langchain_groq) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.75->langchain_groq) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.75->langchain_groq) (2.5.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install langgraph\n",
        "!pip install langchain_groq"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **STATE**"
      ],
      "metadata": {
        "id": "aWkyv9A0Of8e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Annotated, TypedDict\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages\n",
        "class State(TypedDict):\n",
        "  #list of messages\n",
        "  messages : Annotated[list,add_messages]\n",
        "builder = StateGraph(State)"
      ],
      "metadata": {
        "id": "j1R7tIdGDwXe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Noeud1: LLM Call**"
      ],
      "metadata": {
        "id": "WjtbmsXyOn04"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "# Prompt to enter the Groq API key securely (won't show on screen)\n",
        "os.environ[\"GROQ_API_KEY\"] = getpass(\"Enter your Groq API key: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_IDoZPdEG-zT",
        "outputId": "3570b97e-6837-41ea-aa04-6a4132ab474c"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your Groq API key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_groq import ChatGroq\n",
        "llm = ChatGroq(model=\"openai/gpt-oss-20b\")"
      ],
      "metadata": {
        "id": "wrr5SjIDDUN_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def chatbot(state: State):\n",
        " answer = llm.invoke(state[\"messages\"])\n",
        " return {\"messages\": [answer]}\n",
        "builder.add_node(\"chatbot\", chatbot)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2U8NtcqFuyR",
        "outputId": "43ec362f-77e0-47d7-ae9a-fa1d0bca53e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7c17adabcbf0>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Construire Le graph**"
      ],
      "metadata": {
        "id": "9gs1ZhdtOtk0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "builder.add_edge(START,\"chatbot\")\n",
        "builder.add_edge(\"chatbot\",END)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8fyEx1QJiRg",
        "outputId": "c76ce4ce-0b54-46c7-c51f-a71bebd62027"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7c17adabcbf0>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "graph = builder.compile()\n"
      ],
      "metadata": {
        "id": "WoCbA-VUL6g0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "display(Image(graph.get_graph().draw_mermaid_png()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "id": "YCp7AQBJQPz1",
        "outputId": "7be5be17-ea7e-49a0-b22a-3cbc5008bfb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Execution**"
      ],
      "metadata": {
        "id": "bjC6lbJ6O1t-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import (\n",
        " AIMessage,\n",
        " HumanMessage,\n",
        " SystemMessage)"
      ],
      "metadata": {
        "id": "xR4QnOD9JzAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = {\"messages\": [HumanMessage('hi!')]}\n",
        "graph.invoke(input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rikqIZOMVw6",
        "outputId": "8ac06d82-ce68-432f-dddd-744a8f0b607c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'messages': [HumanMessage(content='hi!', additional_kwargs={}, response_metadata={}, id='fb7e79d6-e817-42c2-bd0e-6340955e24fc'),\n",
              "  AIMessage(content='Hello! 👋 How can I assist you today?', additional_kwargs={'reasoning_content': 'User says \"hi!\" It\\'s a greeting. We need to respond politely. Possibly ask how we can help.'}, response_metadata={'token_usage': {'completion_tokens': 43, 'prompt_tokens': 73, 'total_tokens': 116, 'completion_time': 0.042041414, 'prompt_time': 0.00351099, 'queue_time': 0.199852643, 'total_time': 0.045552404}, 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_77f8660d1d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--154009ac-6eea-4e0e-9e80-52b990546a39-0', usage_metadata={'input_tokens': 73, 'output_tokens': 43, 'total_tokens': 116})]}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Memoire checkpointers**"
      ],
      "metadata": {
        "id": "0Y0jtWpeMpeE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input = {\"messages\": [HumanMessage('hi my name is Maha !')]}\n",
        "graph.invoke(input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnVxU7-qMl57",
        "outputId": "c581727c-0e20-401c-c447-96b4df5555b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'messages': [HumanMessage(content='hi my name is Maha !', additional_kwargs={}, response_metadata={}, id='9c8d68e4-87dc-4b70-b332-65cb7e4128a7'),\n",
              "  AIMessage(content='Hello Maha! 👋 How can I help you today?', additional_kwargs={'reasoning_content': 'The user says \"hi my name is Maha!\". We should respond with friendly greeting. According to the policies, no disallowed content. It\\'s a normal greeting. We should ask how to help or what they\\'d like to talk about. Also, we should respect that we are an AI, no personal info. Just respond politely.'}, response_metadata={'token_usage': {'completion_tokens': 87, 'prompt_tokens': 77, 'total_tokens': 164, 'completion_time': 0.086891019, 'prompt_time': 0.003663994, 'queue_time': 0.20084398, 'total_time': 0.090555013}, 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_e99e93f2ac', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--327bd552-0b49-41a4-8af5-e3822081bde6-0', usage_metadata={'input_tokens': 77, 'output_tokens': 87, 'total_tokens': 164})]}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input = {\"messages\": [HumanMessage('What is my Name !')]}\n",
        "graph.invoke(input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1lloUHItM3WF",
        "outputId": "58070f13-a6c6-43b2-fedc-8fe8918fab34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'messages': [HumanMessage(content='What is my Name !', additional_kwargs={}, response_metadata={}, id='ce8897d0-9ad8-4bd9-a084-be7b57d16f56'),\n",
              "  AIMessage(content='I’m not sure what your name is—could you let me know? If you’d rather not share, that’s perfectly fine too. Just let me know how you’d like me to address you!', additional_kwargs={'reasoning_content': 'The user asks: \"What is my Name !\". This is a bit ambiguous. It might be a joke: they want ChatGPT to guess or ask. We need to respond appropriately. The user hasn\\'t provided their name. We might ask them or respond that we don\\'t know. According to policy, we should not fabricate personal info. So we should respond politely: I don\\'t know your name, but you can tell me. Also we can ask if they want to share. We should not assume. Also we should maintain a friendly tone. There\\'s no policy violation. Just respond.'}, response_metadata={'token_usage': {'completion_tokens': 167, 'prompt_tokens': 76, 'total_tokens': 243, 'completion_time': 0.168939848, 'prompt_time': 0.005133564, 'queue_time': 0.275415925, 'total_time': 0.174073412}, 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_80501ff3a1', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--eb45471c-8b3d-4932-91be-a809b0aaa91e-0', usage_metadata={'input_tokens': 76, 'output_tokens': 167, 'total_tokens': 243})]}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Checkpoints:**\n",
        "* offrent une memoire native (memoire short term)\n",
        "* ces sont des objets qu'on peut les stoker dans une bases des donnees\n",
        "* enregistrent le state  du graphe a chaque etape d'execution\n",
        "\n"
      ],
      "metadata": {
        "id": "p_FZmBCnQtVw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "graph = builder.compile(checkpointer=MemorySaver())\n",
        "thread1 = {\"configurable\": {\"thread_id\": \"1\"}}\n",
        "result_1 = graph.invoke(\n",
        " { \"messages\": [HumanMessage(\"hi, my name is Maha!\")] },\n",
        " thread1\n",
        ")\n",
        "print(result_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0wEe396i7Ua",
        "outputId": "538ed528-edb2-4080-d568-48fa9c608ef5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'messages': [HumanMessage(content='hi, my name is Maha!', additional_kwargs={}, response_metadata={}, id='bd35d61e-e284-4e39-9e14-f3c7aaab2aff'), AIMessage(content='Hello, Maha! 👋 How can I assist you today?', additional_kwargs={'reasoning_content': 'The user says \"hi, my name is Maha!\". We need to respond. The system says \"You are ChatGPT...\". There\\'s no instruction for a particular style. The user is greeting. We should respond politely. We can ask how we can help.'}, response_metadata={'token_usage': {'completion_tokens': 75, 'prompt_tokens': 78, 'total_tokens': 153, 'completion_time': 0.07480778, 'prompt_time': 0.003744353, 'queue_time': 0.199828503, 'total_time': 0.078552133}, 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_77f8660d1d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--194fa86d-b270-430b-b136-aa8740d94c16-0', usage_metadata={'input_tokens': 78, 'output_tokens': 75, 'total_tokens': 153})]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result_2 = graph.invoke(\n",
        " { \"messages\": [HumanMessage(\"what is my name?\")] },\n",
        " thread1\n",
        ")\n",
        "#print(result_2)\n",
        "print(\"stat2\",graph.get_state(thread1))\n",
        "for i in graph.get_state(thread1)[0]['messages']:\n",
        "  if isinstance(i,AIMessage):\n",
        "    print(\"AI message:\",i.content)\n",
        "    print(i.additional_kwargs)\n",
        "  if isinstance(i,HumanMessage):\n",
        "    print(\"Human message:\",i.content)\n",
        "    print(\"###########\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "si82uq2mTudo",
        "outputId": "b2c489a8-ead1-442d-99f6-74c3e155e26f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "stat2 StateSnapshot(values={'messages': [HumanMessage(content='hi, my name is Maha!', additional_kwargs={}, response_metadata={}, id='bd35d61e-e284-4e39-9e14-f3c7aaab2aff'), AIMessage(content='Hello, Maha! 👋 How can I assist you today?', additional_kwargs={'reasoning_content': 'The user says \"hi, my name is Maha!\". We need to respond. The system says \"You are ChatGPT...\". There\\'s no instruction for a particular style. The user is greeting. We should respond politely. We can ask how we can help.'}, response_metadata={'token_usage': {'completion_tokens': 75, 'prompt_tokens': 78, 'total_tokens': 153, 'completion_time': 0.07480778, 'prompt_time': 0.003744353, 'queue_time': 0.199828503, 'total_time': 0.078552133}, 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_77f8660d1d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--194fa86d-b270-430b-b136-aa8740d94c16-0', usage_metadata={'input_tokens': 78, 'output_tokens': 75, 'total_tokens': 153}), HumanMessage(content='what is my name?', additional_kwargs={}, response_metadata={}, id='9325ac62-957f-4f98-8a82-8f9445e377c1'), AIMessage(content='Your name is Maha.', additional_kwargs={'reasoning_content': 'We have to answer: user says their name is Maha. So answer: \"Your name is Maha.\" We should be concise.'}, response_metadata={'token_usage': {'completion_tokens': 41, 'prompt_tokens': 106, 'total_tokens': 147, 'completion_time': 0.040090943, 'prompt_time': 0.0050924, 'queue_time': 0.200735569, 'total_time': 0.045183343}, 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_3d587a02fb', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--9df4f473-ab39-427e-89b2-06dce5fccb47-0', usage_metadata={'input_tokens': 106, 'output_tokens': 41, 'total_tokens': 147})]}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0a45b2-5aba-6f67-8004-62c9b8f272b1'}}, metadata={'source': 'loop', 'step': 4, 'parents': {}}, created_at='2025-10-08T15:26:22.947279+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0a45b2-56d9-6fa8-8003-a4a271f4a11a'}}, tasks=(), interrupts=())\n",
            "Human message: hi, my name is Maha!\n",
            "###########\n",
            "AI message: Hello, Maha! 👋 How can I assist you today?\n",
            "{'reasoning_content': 'The user says \"hi, my name is Maha!\". We need to respond. The system says \"You are ChatGPT...\". There\\'s no instruction for a particular style. The user is greeting. We should respond politely. We can ask how we can help.'}\n",
            "Human message: what is my name?\n",
            "###########\n",
            "AI message: Your name is Maha.\n",
            "{'reasoning_content': 'We have to answer: user says their name is Maha. So answer: \"Your name is Maha.\" We should be concise.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "state_history = graph.get_state_history(thread1)\n",
        "for state in state_history:\n",
        "    print(state)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDzJSBzqYXdR",
        "outputId": "0b87dda6-aac8-480f-eb06-8e231541488b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "StateSnapshot(values={'messages': [HumanMessage(content='hi, my name is Maha!', additional_kwargs={}, response_metadata={}, id='bd35d61e-e284-4e39-9e14-f3c7aaab2aff'), AIMessage(content='Hello, Maha! 👋 How can I assist you today?', additional_kwargs={'reasoning_content': 'The user says \"hi, my name is Maha!\". We need to respond. The system says \"You are ChatGPT...\". There\\'s no instruction for a particular style. The user is greeting. We should respond politely. We can ask how we can help.'}, response_metadata={'token_usage': {'completion_tokens': 75, 'prompt_tokens': 78, 'total_tokens': 153, 'completion_time': 0.07480778, 'prompt_time': 0.003744353, 'queue_time': 0.199828503, 'total_time': 0.078552133}, 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_77f8660d1d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--194fa86d-b270-430b-b136-aa8740d94c16-0', usage_metadata={'input_tokens': 78, 'output_tokens': 75, 'total_tokens': 153}), HumanMessage(content='what is my name?', additional_kwargs={}, response_metadata={}, id='9325ac62-957f-4f98-8a82-8f9445e377c1'), AIMessage(content='Your name is Maha.', additional_kwargs={'reasoning_content': 'We have to answer: user says their name is Maha. So answer: \"Your name is Maha.\" We should be concise.'}, response_metadata={'token_usage': {'completion_tokens': 41, 'prompt_tokens': 106, 'total_tokens': 147, 'completion_time': 0.040090943, 'prompt_time': 0.0050924, 'queue_time': 0.200735569, 'total_time': 0.045183343}, 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_3d587a02fb', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--9df4f473-ab39-427e-89b2-06dce5fccb47-0', usage_metadata={'input_tokens': 106, 'output_tokens': 41, 'total_tokens': 147})]}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0a45b2-5aba-6f67-8004-62c9b8f272b1'}}, metadata={'source': 'loop', 'step': 4, 'parents': {}}, created_at='2025-10-08T15:26:22.947279+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0a45b2-56d9-6fa8-8003-a4a271f4a11a'}}, tasks=(), interrupts=())\n",
            "StateSnapshot(values={'messages': [HumanMessage(content='hi, my name is Maha!', additional_kwargs={}, response_metadata={}, id='bd35d61e-e284-4e39-9e14-f3c7aaab2aff'), AIMessage(content='Hello, Maha! 👋 How can I assist you today?', additional_kwargs={'reasoning_content': 'The user says \"hi, my name is Maha!\". We need to respond. The system says \"You are ChatGPT...\". There\\'s no instruction for a particular style. The user is greeting. We should respond politely. We can ask how we can help.'}, response_metadata={'token_usage': {'completion_tokens': 75, 'prompt_tokens': 78, 'total_tokens': 153, 'completion_time': 0.07480778, 'prompt_time': 0.003744353, 'queue_time': 0.199828503, 'total_time': 0.078552133}, 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_77f8660d1d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--194fa86d-b270-430b-b136-aa8740d94c16-0', usage_metadata={'input_tokens': 78, 'output_tokens': 75, 'total_tokens': 153}), HumanMessage(content='what is my name?', additional_kwargs={}, response_metadata={}, id='9325ac62-957f-4f98-8a82-8f9445e377c1')]}, next=('chatbot',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0a45b2-56d9-6fa8-8003-a4a271f4a11a'}}, metadata={'source': 'loop', 'step': 3, 'parents': {}}, created_at='2025-10-08T15:26:22.540562+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0a45b2-56d6-68c8-8002-9912b8084a2a'}}, tasks=(PregelTask(id='008d8015-2920-ee7a-ec2f-446c07a1803f', name='chatbot', path=('__pregel_pull', 'chatbot'), error=None, interrupts=(), state=None, result={'messages': [AIMessage(content='Your name is Maha.', additional_kwargs={'reasoning_content': 'We have to answer: user says their name is Maha. So answer: \"Your name is Maha.\" We should be concise.'}, response_metadata={'token_usage': {'completion_tokens': 41, 'prompt_tokens': 106, 'total_tokens': 147, 'completion_time': 0.040090943, 'prompt_time': 0.0050924, 'queue_time': 0.200735569, 'total_time': 0.045183343}, 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_3d587a02fb', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--9df4f473-ab39-427e-89b2-06dce5fccb47-0', usage_metadata={'input_tokens': 106, 'output_tokens': 41, 'total_tokens': 147})]}),), interrupts=())\n",
            "StateSnapshot(values={'messages': [HumanMessage(content='hi, my name is Maha!', additional_kwargs={}, response_metadata={}, id='bd35d61e-e284-4e39-9e14-f3c7aaab2aff'), AIMessage(content='Hello, Maha! 👋 How can I assist you today?', additional_kwargs={'reasoning_content': 'The user says \"hi, my name is Maha!\". We need to respond. The system says \"You are ChatGPT...\". There\\'s no instruction for a particular style. The user is greeting. We should respond politely. We can ask how we can help.'}, response_metadata={'token_usage': {'completion_tokens': 75, 'prompt_tokens': 78, 'total_tokens': 153, 'completion_time': 0.07480778, 'prompt_time': 0.003744353, 'queue_time': 0.199828503, 'total_time': 0.078552133}, 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_77f8660d1d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--194fa86d-b270-430b-b136-aa8740d94c16-0', usage_metadata={'input_tokens': 78, 'output_tokens': 75, 'total_tokens': 153})]}, next=('__start__',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0a45b2-56d6-68c8-8002-9912b8084a2a'}}, metadata={'source': 'input', 'step': 2, 'parents': {}}, created_at='2025-10-08T15:26:22.539152+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0a45b1-04d6-6a6c-8001-fc2cc4051be2'}}, tasks=(PregelTask(id='3869dd32-6f51-9270-ebcd-8ff89cf2821d', name='__start__', path=('__pregel_pull', '__start__'), error=None, interrupts=(), state=None, result={'messages': [HumanMessage(content='what is my name?', additional_kwargs={}, response_metadata={}, id='9325ac62-957f-4f98-8a82-8f9445e377c1')]}),), interrupts=())\n",
            "StateSnapshot(values={'messages': [HumanMessage(content='hi, my name is Maha!', additional_kwargs={}, response_metadata={}, id='bd35d61e-e284-4e39-9e14-f3c7aaab2aff'), AIMessage(content='Hello, Maha! 👋 How can I assist you today?', additional_kwargs={'reasoning_content': 'The user says \"hi, my name is Maha!\". We need to respond. The system says \"You are ChatGPT...\". There\\'s no instruction for a particular style. The user is greeting. We should respond politely. We can ask how we can help.'}, response_metadata={'token_usage': {'completion_tokens': 75, 'prompt_tokens': 78, 'total_tokens': 153, 'completion_time': 0.07480778, 'prompt_time': 0.003744353, 'queue_time': 0.199828503, 'total_time': 0.078552133}, 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_77f8660d1d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--194fa86d-b270-430b-b136-aa8740d94c16-0', usage_metadata={'input_tokens': 78, 'output_tokens': 75, 'total_tokens': 153})]}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0a45b1-04d6-6a6c-8001-fc2cc4051be2'}}, metadata={'source': 'loop', 'step': 1, 'parents': {}}, created_at='2025-10-08T15:25:47.097308+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0a45b1-00a3-6d92-8000-af2d7565e752'}}, tasks=(), interrupts=())\n",
            "StateSnapshot(values={'messages': [HumanMessage(content='hi, my name is Maha!', additional_kwargs={}, response_metadata={}, id='bd35d61e-e284-4e39-9e14-f3c7aaab2aff')]}, next=('chatbot',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0a45b1-00a3-6d92-8000-af2d7565e752'}}, metadata={'source': 'loop', 'step': 0, 'parents': {}}, created_at='2025-10-08T15:25:46.657089+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0a45b1-00a0-65bf-bfff-09182723361c'}}, tasks=(PregelTask(id='c3c3d259-8799-90a4-69e2-44386331a39a', name='chatbot', path=('__pregel_pull', 'chatbot'), error=None, interrupts=(), state=None, result={'messages': [AIMessage(content='Hello, Maha! 👋 How can I assist you today?', additional_kwargs={'reasoning_content': 'The user says \"hi, my name is Maha!\". We need to respond. The system says \"You are ChatGPT...\". There\\'s no instruction for a particular style. The user is greeting. We should respond politely. We can ask how we can help.'}, response_metadata={'token_usage': {'completion_tokens': 75, 'prompt_tokens': 78, 'total_tokens': 153, 'completion_time': 0.07480778, 'prompt_time': 0.003744353, 'queue_time': 0.199828503, 'total_time': 0.078552133}, 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_77f8660d1d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--194fa86d-b270-430b-b136-aa8740d94c16-0', usage_metadata={'input_tokens': 78, 'output_tokens': 75, 'total_tokens': 153})]}),), interrupts=())\n",
            "StateSnapshot(values={'messages': []}, next=('__start__',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0a45b1-00a0-65bf-bfff-09182723361c'}}, metadata={'source': 'input', 'step': -1, 'parents': {}}, created_at='2025-10-08T15:25:46.655659+00:00', parent_config=None, tasks=(PregelTask(id='d4775b91-e684-7af5-8cd3-0b6d78e93aa4', name='__start__', path=('__pregel_pull', '__start__'), error=None, interrupts=(), state=None, result={'messages': [HumanMessage(content='hi, my name is Maha!', additional_kwargs={}, response_metadata={}, id='bd35d61e-e284-4e39-9e14-f3c7aaab2aff')]}),), interrupts=())\n"
          ]
        }
      ]
    }
  ]
}